#!/usr/bin/env python
# coding: utf-8

# In[1]:


# for numerical computing
import numpy as np

# for dataframes
import pandas as pd

# for easier visualization
import seaborn as sns

# for visualization and to display plots
from matplotlib import pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')

# import color maps
from matplotlib.colors import ListedColormap

# Ignore Warnings
import warnings
warnings.filterwarnings("ignore")

from math import sqrt

# to split train and test set
from sklearn.model_selection import train_test_split

# to perform hyperparameter tuning
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV

from sklearn.model_selection import cross_val_score

# Machine Learning Models
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from matplotlib.colors import ListedColormap
from sklearn.metrics import accuracy_score
#import xgboost
import os
mingw_path = 'C:\\Program Files\\mingw-w64\\x86_64-7.2.0-posix-seh-rt_v5-rev0\\mingw64\\bin'
os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']
from xgboost import XGBClassifier
from xgboost import plot_importance  
# to plot feature importance


# In[2]:


df=pd.read_csv('indian_liver_patient.csv')


# In[3]:


df.shape


# In[4]:


df.columns


# In[5]:


df.head()


# In[6]:


df.dtypes[df.dtypes=='object']


# In[7]:


# Plot histogram grid
df.hist(figsize=(15,15), xrot=-45, bins=10) ## Display the labels rotated by 45 degress

# Clear the text "residue"
plt.show()


# In[8]:


df.describe()


# In[9]:


## if score==negative, mark 0 ;else 1 
def partition(x):
    if x == 2:
        return 0
    return 1

df['Dataset'] = df['Dataset'].map(partition)


# In[10]:


df.describe(include=['object'])


# In[11]:


plt.figure(figsize=(5,5))
sns.countplot(y='Gender', data=df)


# In[12]:


df[df['Gender'] == 'Male'][['Dataset', 'Gender']].head()


# In[13]:


sns.factorplot (x="Age", y="Gender", hue="Dataset", data=df);


# In[14]:


sns.countplot(data=df, x = 'Gender', label='Count')

M, F = df['Gender'].value_counts()
print('Number of patients that are male: ',M)
print('Number of patients that are female: ',F)


# In[15]:


## if score==negative, mark 0 ;else 1 
def partition(x):
    if x =='Male':
        return 0
    return 1

df['Gender'] = df['Gender'].map(partition)


# In[16]:


sns.set_style('whitegrid')   ## Background Grid
sns.FacetGrid(df, hue = 'Dataset', size = 5).map(plt.scatter, 'Total_Bilirubin', 'Direct_Bilirubin').add_legend()


# In[17]:


sns.set_style('whitegrid')   ## Background Grid
sns.FacetGrid(df, hue = 'Dataset', size = 5).map(plt.scatter, 'Total_Bilirubin', 'Albumin').add_legend()


# In[18]:


sns.set_style('whitegrid')   ## Background Grid
sns.FacetGrid(df, hue = 'Dataset', size = 5).map(plt.scatter, 'Total_Protiens', 'Albumin_and_Globulin_Ratio').add_legend()


# In[19]:


df.corr()


# In[20]:


plt.figure(figsize=(10,10))
sns.heatmap(df.corr())


# In[21]:


mask=np.zeros_like(df.corr())
mask[np.triu_indices_from(mask)] = True
plt.figure(figsize=(10,10))
with sns.axes_style("white"):
    ax = sns.heatmap(df.corr()*100, mask=mask, fmt='.0f', annot=True, lw=1, cmap=ListedColormap(['green', 'yellow', 'red','blue']))


# In[22]:


df = df.drop_duplicates()
print( df.shape )


# In[23]:


sns.boxplot(df.Aspartate_Aminotransferase)


# In[24]:


df.Aspartate_Aminotransferase.sort_values(ascending=False).head()


# In[25]:


df = df[df.Aspartate_Aminotransferase <=3000 ]
df.shape


# In[26]:


sns.boxplot(df.Aspartate_Aminotransferase)


# In[27]:


df.Aspartate_Aminotransferase.sort_values(ascending=False).head()


# In[28]:


df = df[df.Aspartate_Aminotransferase <=2500 ]
df.shape


# In[29]:


df.isnull().values.any()


# In[30]:


df=df.dropna(how='any')


# In[31]:


df.shape


# In[32]:


df.head()


# In[33]:


# Create separate object for target variable
y = df.Dataset

# Create separate object for input features
X = df.drop('Dataset', axis=1)


# In[34]:


# Split X and y into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size=0.2, 
                                                    random_state=1234,
                                                    stratify=df.Dataset)


# In[35]:


# Print number of observations in X_train, X_test, y_train, and y_test
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)


# In[36]:


train_mean = X_train.mean()
train_std = X_train.std()


# In[37]:


## Standardize the train data set
X_train = (X_train - train_mean) / train_std


# In[38]:


## Check for mean and std dev.
X_train.describe()


# In[39]:


## Note: We use train_mean and train_std_dev to standardize test data set
X_test = (X_test - train_mean) / train_std


# In[40]:


## Check for mean and std dev. - not exactly 0 and 1
X_test.describe()


# In[41]:


tuned_params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], 'penalty': ['l1', 'l2']}
model = GridSearchCV(LogisticRegression(), tuned_params, scoring = 'roc_auc', n_jobs=-1)
model.fit(X_train, y_train)


# In[42]:


model.best_estimator_


# In[43]:


## Predict Train set results
y_train_pred = model.predict(X_train)


# In[44]:


## Predict Test set results
y_pred = model.predict(X_test)


# In[45]:


# Get just the prediction for the positive class (1)
y_pred_proba = model.predict_proba(X_test)[:,1]


# In[46]:


# Display first 10 predictions
y_pred_proba[:10]


# In[47]:


i=28  ## Change the value of i to get the details of any point (56, 213, etc.)
print('For test point {}, actual class = {}, precited class = {}, predicted probability = {}'.
      format(i, y_test.iloc[i], y_pred[i], y_pred_proba[i]))


# In[48]:


confusion_matrix(y_test, y_pred).T


# In[49]:


# Calculate ROC curve from y_test and pred
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)


# In[50]:


# Plot the ROC curve
fig = plt.figure(figsize=(8,8))
plt.title('Receiver Operating Characteristic')

# Plot ROC curve
plt.plot(fpr, tpr, label='l1')
plt.legend(loc='lower right')

# Diagonal 45 degree line
plt.plot([0,1],[0,1],'k--')

# Axes limits and labels
plt.xlim([-0.1,1.1])
plt.ylim([-0.1,1.1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()


# In[51]:


# Calculate AUC for Train set
print(roc_auc_score(y_train, y_train_pred))


# In[52]:


# Calculate AUC for Test set
print(auc(fpr, tpr))


# In[53]:


## Building the model again with the best hyperparameters
model = LogisticRegression(C=1, penalty = 'l2')
model.fit(X_train, y_train)


# In[54]:


indices = np.argsort(-abs(model.coef_[0,:]))
print("The features in order of importance are:")
print(50*'-')
for feature in X.columns[indices]:
    print(feature)


# In[82]:


# creating odd list of K for KNN
neighbors = list(range(1,20,2))
# empty list that will hold cv scores
cv_scores = []

#  10-fold cross validation , 9 datapoints will be considered for training and 1 for cross validation (turn by turn) to determine value of k
for k in neighbors:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')
    cv_scores.append(scores.mean())   

# changing to misclassification error
MSE = [1 - x for x in cv_scores]

# determining best k
optimal_k = neighbors[MSE.index(min(MSE))]
print('\nThe optimal number of neighbors is %d.' % optimal_k)


# In[83]:


MSE.index(min(MSE))


# In[84]:


# plot misclassification error vs k 
plt.plot(neighbors, MSE)
plt.xlabel('Number of Neighbors K')
plt.ylabel('Misclassification Error')
plt.show()


# In[85]:


classifier = KNeighborsClassifier(n_neighbors = optimal_k)
classifier.fit(X_train, y_train)


# In[86]:


y_pred = classifier.predict(X_test)


# In[87]:


y_train_pred = classifier.predict(X_train)


# In[88]:


acc = accuracy_score(y_test, y_pred, normalize=True) * float(100)  ## get the accuracy on testing data
acc


# In[89]:


cnf=confusion_matrix(y_test,y_pred).T
cnf


# In[90]:


# Get just the prediction for the positive class (1)
y_pred_proba = classifier.predict_proba(X_test)[:,1]


# In[91]:


# Display first 10 predictions
y_pred_proba[:10]


# In[92]:


# Calculate ROC curve from y_test and pred
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)


# In[93]:


# Plot the ROC curve
fig = plt.figure(figsize=(8,8))
plt.title('Receiver Operating Characteristic')

# Plot ROC curve
plt.plot(fpr, tpr, label='l1')
plt.legend(loc='lower right')

# Diagonal 45 degree line
plt.plot([0,1],[0,1],'k--')

# Axes limits and labels
plt.xlim([-0.1,1.1])
plt.ylim([-0.1,1.1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()


# In[94]:


# Calculate AUC for Train
roc_auc_score(y_train, y_train_pred)


# In[95]:


# Calculate AUC for Test
print(auc(fpr, tpr))


# In[109]:


from sklearn import svm
def svc_param_selection(X, y, nfolds):
    Cs = [0.001, 0.01, 0.1, 1, 10]
    gammas = [0.001, 0.01, 0.1, 1]
    param_grid = {'C': Cs, 'gamma' : gammas}
    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)
    grid_search.fit(X_train, y_train)
    grid_search.best_params_
    return grid_search.best_params_


# In[110]:


svClassifier=SVC(kernel='rbf',probability=True)
svClassifier.fit(X_train,y_train)


# In[111]:


svc_param_selection(X_train,y_train,5)


# In[112]:


###### Building the model again with the best hyperparameters
model = SVC(C=1, gamma=1)
model.fit(X_train, y_train)


# In[113]:


## Predict Train results
y_train_pred = model.predict(X_train)


# In[114]:


## Predict Test results
y_pred = model.predict(X_test)


# In[115]:


confusion_matrix(y_test, y_pred).T


# In[117]:


# Calculate ROC curve from y_test and pred
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)


# In[118]:


# Plot the ROC curve
fig = plt.figure(figsize=(8,8))
plt.title('Receiver Operating Characteristic')

# Plot ROC curve
plt.plot(fpr, tpr, label='l1')
plt.legend(loc='lower right')

# Diagonal 45 degree line
plt.plot([0,1],[0,1],'k--')

# Axes limits and labels
plt.xlim([-0.1,1.1])
plt.ylim([-0.1,1.1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()


# In[119]:


# Calculate AUC for Train
roc_auc_score(y_train, y_train_pred)


# In[120]:


print(auc(fpr, tpr))


# In[130]:


# Neural Networks# Neural 
neural = MLPClassifier(hidden_layer_sizes=40,
                     activation='relu',
                     solver='adam',
                     alpha=0.001,
                     batch_size='auto',
                     max_iter=200,
                     random_state=137,
                     tol=0.0001,
                     early_stopping=False,
                     validation_fraction=0.1,
                     beta_1=0.9,
                     beta_2=0.999,
                     epsilon=1e-08,
                     learning_rate='constant',
                     power_t=0.5,
                     momentum=0.8,
                     nesterovs_momentum=True,
                     shuffle=True,
                     learning_rate_init=0.001)
neural.fit(X_train, y_train)
#Predict Output
predicted = neural.predict(X_test)

neural_score = round(neural.score(X_train, y_train) * 100, 2)
neural_score_test = round(neural.score(X_test, y_test) * 100, 2)
print('Neural Score: \n', neural_score)
print('Neural Test Score: \n', neural_score_test)
print('Accuracy: \n', accuracy_score(y_test, predicted))
print(confusion_matrix(predicted,y_test))
print(classification_report(y_test,predicted))


# In[131]:


## Predict Train results
y_train_pred = neural.predict(X_train)


# In[132]:


## Predict Test results
y_pred = neural.predict(X_test)


# In[133]:


# Calculate ROC curve from y_test and pred
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)


# In[134]:


# Plot the ROC curve
fig = plt.figure(figsize=(8,8))
plt.title('Receiver Operating Characteristic')

# Plot ROC curve
plt.plot(fpr, tpr, label='l1')
plt.legend(loc='lower right')

# Diagonal 45 degree line
plt.plot([0,1],[0,1],'k--')

# Axes limits and labels
plt.xlim([-0.1,1.1])
plt.ylim([-0.1,1.1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()


# In[135]:


roc_auc_score(y_train,y_train_pred )


# In[136]:


# Calculate AUC for Test
print(auc(fpr, tpr))
